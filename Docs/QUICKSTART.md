# üöÄ Gu√≠a de Inicio R√°pido - Orquestador Multi-IA

## Requisitos Previos

### 1. Ollama (Motor de IA)
Ollama debe estar instalado y corriendo con los modelos descargados.

**Instalar Ollama:**
```powershell
# Descarga desde: https://ollama.ai/download
# O usando winget:
winget install Ollama.Ollama
```

**Descargar modelos:**
```powershell
ollama pull llama3.2    # 2GB - Conversaci√≥n general
ollama pull codellama   # 3.8GB - An√°lisis de c√≥digo  
ollama pull mistral     # 4.1GB - An√°lisis de datos
```

**Verificar Ollama:**
```powershell
# Debe responder con la versi√≥n
ollama --version

# Verificar que los modelos est√©n instalados
ollama list
```

### 2. Python 3.11+
```powershell
python --version  # Debe ser 3.11 o superior
```

### 3. Node.js (para frontend)
```powershell
node --version   # Ya instalado seg√∫n tu setup
```

---

## üéØ Pasos para Iniciar el Sistema Completo

### Opci√≥n A: Inicio Autom√°tico (Recomendado)

Desde la ra√≠z del proyecto:

```powershell
# Terminal 1 - Iniciar Orquestador Backend
.\Scripts\start-orchestrator-dev.ps1

# Terminal 2 - Iniciar Frontend VR (en otra terminal)
.\Scripts\start-front-dev.ps1
```

### Opci√≥n B: Inicio Manual

**Terminal 1 - Backend:**
```powershell
cd Api\orchestrator
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
python -m uvicorn main:app --reload --port 8000
```

**Terminal 2 - Frontend:**
```powershell
cd App\frontend-vr
npm install
npm run dev
```

---

## ‚úÖ Verificaci√≥n del Sistema

### 1. Verificar Ollama
```powershell
# Debe devolver "Ollama is running"
curl http://localhost:11434
```

### 2. Verificar Orquestador
```powershell
# Debe devolver {"status":"healthy",...}
curl http://localhost:8000/health
```

### 3. Verificar Frontend
Abre http://localhost:3000 en el navegador

---

## üîß Configuraci√≥n del Frontend

En `App/frontend-vr/src/config.js`:

```javascript
export const CONFIG = {
    API_BASE_URL: 'http://localhost:8000',
    
    // Cambiar seg√∫n disponibilidad del backend:
    MOCK_MODE: false,  // false = usa backend real
                       // true  = usa datos simulados
    // ...
}
```

---

## üß™ Probar el Sistema

### 1. Desde el Frontend VR

1. Abre http://localhost:3000
2. Espera a que cargue la escena VR
3. Ver√°s:
   - Orquestador dorado en el centro
   - 3 agentes orbitando (azul, morado, naranja)
   
4. **Hacer una pregunta:**
   - Click en el campo de texto
   - Escribe: "como te llamas"
   - Click en "SEND CUSTOM QUERY"
   - Espera ~3-5 segundos
   - Aparecer√° un panel con:
     - Respuesta del orquestador
     - Respuestas de los 3 agentes IA
     - S√≠ntesis final

5. **Atajos de teclado:**
   - `Q` - Mostrar/ocultar panel de queries
   - `C` - Mostrar/ocultar creador de agentes
   - `M` - Toggle modo Mock on/off

### 2. Desde la API (Swagger)

Abre http://localhost:8000/docs

**Endpoints disponibles:**

- `GET /health` - Estado del sistema
- `GET /agents` - Listar agentes
- `POST /query` - Enviar query
  ```json
  {
    "query": "como te llamas",
    "use_agents": true
  }
  ```

### 3. Desde PowerShell

```powershell
# Query simple
$body = @{
    query = "como te llamas"
    use_agents = $true
} | ConvertTo-Json

Invoke-RestMethod -Method Post `
    -Uri "http://localhost:8000/query" `
    -ContentType "application/json" `
    -Body $body
```

---

## üìä Flujo de Procesamiento

```
Usuario ‚Üí Frontend VR
            ‚Üì
    Query: "como te llamas"
            ‚Üì
    Orquestador (FastAPI)
            ‚Üì
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚Üì                ‚Üì
1. Razonamiento   2. Consulta Agentes (paralelo)
   Propio             ‚îú‚îÄ Code Analyzer (codellama)
   (llama3.2)         ‚îú‚îÄ Data Analyst (mistral)
                      ‚îî‚îÄ Conversation Agent (llama3.2)
            ‚Üì
    3. S√≠ntesis de Respuestas
            ‚Üì
    Respuesta Final ‚Üí Frontend VR
```

---

## üéÆ Modo VR

Click en el bot√≥n **"VR MODE"** (esquina inferior izquierda) para entrar en modo inmersivo con visor VR.

---

## üêõ Troubleshooting

### "Connection refused" en el frontend

**Causa:** Backend no est√° corriendo o Ollama no est√° activo

**Soluci√≥n:**
```powershell
# Verificar Ollama
curl http://localhost:11434

# Si no responde, iniciar Ollama
ollama serve

# Verificar Backend
curl http://localhost:8000/health

# Si no responde, iniciar backend
.\Scripts\start-orchestrator-dev.ps1
```

### "Model not found" en el backend

**Causa:** Modelos de Ollama no descargados

**Soluci√≥n:**
```powershell
ollama pull llama3.2
ollama pull codellama
ollama pull mistral
```

### Frontend en modo Mock

**Causa:** `MOCK_MODE: true` en config.js

**Soluci√≥n:**
```javascript
// En App/frontend-vr/src/config.js
MOCK_MODE: false,  // Cambiar a false
```

Recargar navegador con Ctrl+F5

---

## üìù Ejemplo de Query Completa

**Query:** "Analiza la calidad de este c√≥digo"

**Respuesta esperada:**

```
Respuesta del Orquestador:
Para analizar calidad de c√≥digo necesito ver el c√≥digo espec√≠fico...

Perspectivas de Agentes Especializados:

‚Ä¢ Code Analyzer (codellama): 
  El an√°lisis de calidad incluye m√©tricas de complejidad ciclom√°tica,
  adherencia a principios SOLID, cobertura de tests...

‚Ä¢ Data Analyst (mistral):
  Desde la perspectiva de an√°lisis, evaluar√≠a m√©tricas cuantitativas
  como LOC, duplicaci√≥n, deuda t√©cnica...

‚Ä¢ Conversation Agent (llama3.2):
  Para ayudarte mejor, ¬øpodr√≠as compartir el c√≥digo que quieres
  analizar?

S√≠ntesis: Se consultaron 3 agentes especializados. Las respuestas
convergen en proporcionar una perspectiva integral de tu consulta.
```

---

## üéØ Siguiente Paso

Una vez verificado que todo funciona, puedes:

1. ‚úÖ Crear nuevos agentes desde el frontend (bot√≥n C)
2. ‚úÖ Hacer queries complejas
3. ‚úÖ Dockerizar el sistema completo
4. ‚úÖ Agregar ChromaDB para memoria vectorial
5. ‚úÖ Implementar WebSockets para respuestas en tiempo real

---

## üìö Recursos

- **Ollama Docs:** https://ollama.ai/docs
- **FastAPI Docs:** https://fastapi.tiangolo.com
- **A-Frame Docs:** https://aframe.io/docs
- **Proyecto GitHub:** https://github.com/xwill007/MULTI-IA-DOCKER-HEXAGONAL
